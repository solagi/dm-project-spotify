{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import spotipy\n",
    "import pandas as pd\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import numpy as np\n",
    "from src.preprocessing import get_features\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from src.random_generator_w_artists import get_random_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before running this code, a new token needs to be generated in src/random_generator_w_artists.py\n",
    "\n",
    "CLIENT_ID = \"\" #DEFINE YOUR SPOTIPY CREDENTIALS\n",
    "CLIENT_SECRET = \"\" #DEFINE YOUR SPOTIPY CREDENTIALS\n",
    "sp = spotipy.Spotify(client_credentials_manager=SpotifyClientCredentials(client_id=CLIENT_ID, client_secret=CLIENT_SECRET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs_as_list = []\n",
    "directory = os.fsencode('./playlist_data')\n",
    "    \n",
    "for file in os.listdir(directory):\n",
    "     filename = os.fsdecode(file)\n",
    "     if filename.endswith(\".json\"): \n",
    "\n",
    "        playlist = json.load(open('./playlist_data/' + filename))\n",
    "        playlist_id = playlist['id']\n",
    "        playlist_name = playlist['name']\n",
    "        df_playlist = playlist['tracks']\n",
    "        df_tracks = df_playlist['items']\n",
    "\n",
    "        track_ids = []\n",
    "        artists = []\n",
    "        featurings = []\n",
    "        for item in df_tracks:\n",
    "            if item['track'] is not None: \n",
    "                trackID = item['track']['id']\n",
    "                track_ids.append(trackID)\n",
    "                main_artist = item[\"track\"]['artists'][0]['name']\n",
    "                artists.append(main_artist)\n",
    "                number_of_features = len(item[\"track\"][\"artists\"])\n",
    "                featurings.append(number_of_features)\n",
    "                \n",
    "        temp_df = pd.DataFrame({'PlaylistID': playlist_id, 'PlaylistTitle': playlist_name, 'TrackID': track_ids, \"MainArtist\": artists, \"NoFeaturing\": featurings, 'Features': ''})\n",
    "        all_dfs_as_list.append(temp_df)\n",
    "random_df = get_random_df()\n",
    "print('Size of random DF', random_df.shape)\n",
    "all_dfs_as_list.append(random_df)\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None) # Displays the entire dataframe in nootebook, not just a preview\n",
    "df = pd.concat(all_dfs_as_list)\n",
    "print('Before duplicates removed', df.shape)\n",
    "df.drop_duplicates(subset='TrackID', keep=\"first\", inplace=True)\n",
    "print('After duplicates removed', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add musical features to each song\n",
    "i = 0\n",
    "\n",
    "sp = spotipy.Spotify(client_credentials_manager=SpotifyClientCredentials(client_id=CLIENT_ID, client_secret=CLIENT_SECRET))\n",
    "for track in df['TrackID']:\n",
    "    track_ft = 'spotify:audio-features:{}'.format(track)\n",
    "    track_features = sp.audio_features(track_ft)[0]\n",
    "    df[\"Features\"].iloc[i] = np.array(track_features)\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split each feature into a seperate column\n",
    "df[['danceability','energy', 'key', 'loudness', 'mode', 'speechiness','acousticness',\n",
    "    'instrumentalness','liveness','valence', 'tempo', 'type', 'id', 'uri', \n",
    "    'track_href','analysis_url', 'duration_ms','time_signature']] = df.apply(lambda x: get_features(row = x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping redundant columns...\n",
    "df = df.drop(columns=['type', 'Features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Labels added from label_data\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "df[\"Artist\"] = df[\"MainArtist\"].str.lower()\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None) # Displays the entire dataframe in nootebook, not just a preview\n",
    "\n",
    "## Load the CSV files and save in 1 dataframe\n",
    "csv_files = [f for f in listdir(\"label_data\") if isfile(join(\"label_data\", f))]\n",
    "all_results = pd.DataFrame()\n",
    "\n",
    "for i in csv_files:\n",
    "    temp_df = pd.read_csv(\"label_data/\"+i)\n",
    "    all_results = all_results.append(temp_df, ignore_index=True)\n",
    "\n",
    "\n",
    "all_results[\"Artist\"] = all_results[\"Artist\"].str.lower()\n",
    "all_results = all_results.groupby(\"Artist\").first()\n",
    "\n",
    "df_labels = df.join(all_results,on=\"Artist\",how=\"left\")\n",
    "df_labels[\"BigLabel\"] = (df_labels[\"Label\"].notna())\n",
    "\n",
    "df_overview = df_labels.groupby(\"Artist\").count()\n",
    "df_overview.sort_values(by=\"index\", ascending=False)\n",
    "\n",
    "## Save final dataframe\n",
    "#df_labels.to_pickle(\"dataframe_w_labels.pkl\")\n",
    "df = df_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram analysis for analysing value distribution in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_pickle(\"dataframe.pkl\")\n",
    "hist = df.hist(bins=10, figsize=(15,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation analysis for finding any strong relations between all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr(method='pearson')\n",
    "#Pearson - Visual heatmap\n",
    "fig, ax = plt.subplots(figsize=(15,10)) #for size of figure\n",
    "sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns, cmap='RdBu_r', annot=True, linewidth=0.5, ax=ax)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b083f2c209207e721cc347c1e741713b90838bbb41e24a2537d3a4eac09f600b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
